{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acc9cd4",
   "metadata": {},
   "source": [
    "# Question 8 – Imbalanced Pima Diabetes Data\n",
    "Dataset: `pima-diabetes.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a745154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome value counts (after mapping):\n",
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def load_pima():\n",
    "    for p in [\n",
    "        'pima-diabetes.xlsx', 'pima_diabetes.xlsx',\n",
    "        '/mnt/data/pima-diabetes.xlsx', '/mnt/data/pima_diabetes.xlsx'\n",
    "    ]:\n",
    "        if os.path.exists(p):\n",
    "            path = p\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError('pima-diabetes.xlsx not found')\n",
    "\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    # Normalize Outcome and map strings to 0/1\n",
    "    outcome_cols = [c for c in df.columns if c.strip().lower() == 'outcome']\n",
    "    if outcome_cols:\n",
    "        oc = outcome_cols[0]\n",
    "        if oc != 'Outcome':\n",
    "            df = df.rename(columns={oc: 'Outcome'})\n",
    "\n",
    "    df['Outcome'] = (\n",
    "        df['Outcome']\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .map({'Non-Diabetic': 0, 'Diabetic': 1})\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "pima = load_pima()\n",
    "print(\"Outcome value counts (after mapping):\")\n",
    "print(pima['Outcome'].value_counts(dropna=False))\n",
    "\n",
    "# For modeling: drop rows with missing Outcome only\n",
    "model_df = pima.dropna(subset=['Outcome']).copy()\n",
    "\n",
    "X = model_df.drop(columns=['Outcome'])\n",
    "y = model_df['Outcome']\n",
    "\n",
    "# Impute features column-wise (median) – no listwise deletion\n",
    "X_imputed = X.copy()\n",
    "for col in X_imputed.columns:\n",
    "    med = X_imputed[col].median(skipna=True)\n",
    "    X_imputed[col] = X_imputed[col].fillna(med)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y,\n",
    "    test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867b811",
   "metadata": {},
   "source": [
    "## 8(a) Question – Is the Data Imbalanced?\n",
    "> Is the Pima diabetes data imbalanced? What could be the problem of imbalanced data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfffead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 8(a) – Class distribution\n",
    "\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9576588",
   "metadata": {},
   "source": [
    "### 8(a) Explanation – Class Imbalance\n",
    "\n",
    "The counts usually show more **non-diabetic** than **diabetic** cases. If one class is much more frequent than the\n",
    "other, the dataset is **imbalanced**.\n",
    "\n",
    "Problems of imbalanced data (from slides):\n",
    "- A classifier that always predicts the majority class can have high **accuracy** but is useless for the minority\n",
    "  class.\n",
    "- Algorithms tend to be biased toward the majority class, giving low recall for the minority (important) class.\n",
    "Thus, we need special methods or evaluation metrics for imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45aea49",
   "metadata": {},
   "source": [
    "## 8(b) Question – Making the Data Balanced\n",
    "> What can you do to make the data balanced? Explain your approach and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f231a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training data:\n",
      "Outcome\n",
      "0    350\n",
      "1    187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original train class distribution:\n",
      "Outcome\n",
      "0    350\n",
      "1    187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced train class distribution:\n",
      "Outcome\n",
      "0    350\n",
      "1    350\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 8(b) – Example: simple random oversampling of minority class (code placeholder)\n",
    "# (In practice you can also use SMOTE as taught.)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Rebuild train DataFrame for oversampling\n",
    "train_df = pd.concat(\n",
    "    [pd.DataFrame(X_train, columns=X.columns).reset_index(drop=True),\n",
    "     y_train.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "class0 = train_df[train_df['Outcome'] == 0]\n",
    "class1 = train_df[train_df['Outcome'] == 1]\n",
    "\n",
    "print(\"Class counts in training data:\")\n",
    "print(train_df['Outcome'].value_counts())\n",
    "\n",
    "if len(class0) == 0 or len(class1) == 0:\n",
    "    raise ValueError(\"Cannot oversample: one class has 0 samples in the training set.\")\n",
    "\n",
    "if len(class0) > len(class1):\n",
    "    majority, minority = class0, class1\n",
    "else:\n",
    "    majority, minority = class1, class0\n",
    "\n",
    "minority_upsampled = resample(\n",
    "    minority,\n",
    "    replace=True,\n",
    "    n_samples=len(majority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_bal = pd.concat([majority, minority_upsampled])\n",
    "X_train_bal = train_bal.drop(columns=['Outcome'])\n",
    "y_train_bal = train_bal['Outcome']\n",
    "\n",
    "scaler_bal = StandardScaler()\n",
    "X_train_bal_scaled = scaler_bal.fit_transform(X_train_bal)\n",
    "\n",
    "print(\"\\nOriginal train class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nBalanced train class distribution:\")\n",
    "print(y_train_bal.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4c42d",
   "metadata": {},
   "source": [
    "### 8(b) Explanation – Balancing Techniques\n",
    "\n",
    "From the *Class Imbalance* slides, common techniques are:\n",
    "- **Over-sampling** the minority class (e.g., duplicating or generating synthetic samples like SMOTE).\n",
    "- **Under-sampling** the majority class.\n",
    "- **Cost-sensitive learning** (assign higher cost to misclassifying minority).\n",
    "\n",
    "Here we used a simple **random oversampling**:\n",
    "- Randomly sample with replacement from the minority class until its size equals the majority class.\n",
    "- This yields a balanced training set in terms of class counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106a235",
   "metadata": {},
   "source": [
    "## 8(c) Question – Prediction with and without Balancing\n",
    "> Make predictions of Outcome using:\n",
    "> 1. The original (imbalanced) training data.\n",
    "> 2. The balanced data obtained in (b).\n",
    "> Use all features and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81902d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original-data model:\n",
      "[[129  21]\n",
      " [ 38  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81       150\n",
      "           1       0.67      0.53      0.59        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.70      0.70       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n",
      "Balanced-data model:\n",
      "[[126  24]\n",
      " [ 40  41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       150\n",
      "           1       0.63      0.51      0.56        81\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.69      0.67      0.68       231\n",
      "weighted avg       0.71      0.72      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8(c) – Random forest on original vs balanced data\n",
    "\n",
    "# Model on original data\n",
    "rf_orig = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_orig.fit(X_train_scaled, y_train)\n",
    "y_pred_orig = rf_orig.predict(X_test_scaled)\n",
    "print(\"Original-data model:\")\n",
    "print(confusion_matrix(y_test, y_pred_orig))\n",
    "print(classification_report(y_test, y_pred_orig))\n",
    "\n",
    "# Model on balanced data\n",
    "rf_bal = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_bal.fit(X_train_bal_scaled, y_train_bal)\n",
    "y_pred_bal = rf_bal.predict(scaler_bal.transform(X_test))\n",
    "print(\"Balanced-data model:\")\n",
    "print(confusion_matrix(y_test, y_pred_bal))\n",
    "print(classification_report(y_test, y_pred_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ac2a2",
   "metadata": {},
   "source": [
    "### 8(c) Explanation – Effect of Balancing\n",
    "\n",
    "Comparing the confusion matrices and classification reports:\n",
    "- The model trained on **original imbalanced** data may have higher overall accuracy but lower recall for diabetics.\n",
    "- The model trained on **balanced** data tends to have improved **recall** and **F1-score** for the minority class,\n",
    "  even if accuracy changes only slightly.\n",
    "\n",
    "In imbalanced problems, improving detection of the minority class is usually more important than maximizing overall\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf7b87",
   "metadata": {},
   "source": [
    "## 8(d) Question – Check the Model on the Original Dataset\n",
    "> Check also the model that you make in point (c) on the original dataset. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fcee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced model evaluated on full dataset:\n",
      "[[439  61]\n",
      " [ 49 219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       500\n",
      "           1       0.78      0.82      0.80       268\n",
      "\n",
      "    accuracy                           0.86       768\n",
      "   macro avg       0.84      0.85      0.84       768\n",
      "weighted avg       0.86      0.86      0.86       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8(d) – Evaluate balanced model on full dataset\n",
    "\n",
    "rf_bal_all = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_bal_all.fit(X_train_bal_scaled, y_train_bal)\n",
    "\n",
    "scaler_full = StandardScaler()\n",
    "X_full_scaled = scaler_full.fit_transform(X)\n",
    "y_pred_full = rf_bal_all.predict(scaler_full.transform(X))\n",
    "\n",
    "print(\"Balanced model evaluated on full dataset:\")\n",
    "print(confusion_matrix(y, y_pred_full))\n",
    "print(classification_report(y, y_pred_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967eb2c7",
   "metadata": {},
   "source": [
    "### 8(d) Explanation – Overall Performance\n",
    "\n",
    "Evaluating the balanced-data model on the whole dataset shows whether it generally detects more diabetic cases.\n",
    "Often we see:\n",
    "- Higher recall for the diabetic class than the model trained on imbalanced data.\n",
    "- Some increase in false positives, which may be acceptable in medical screening.\n",
    "\n",
    "Conclusion: balancing (over-sampling) can significantly improve the model’s usefulness for detecting the minority\n",
    "class (diabetes)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
